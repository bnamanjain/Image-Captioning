# Image-Captioning
Here, My goal was to make an AI tool which would use Image-Captioning and give out the caption related to the image. I have used a pre-trained model from HuggingFace.com. Refer read_me for more. Thanks

First i went to huggingface.com, from where one download pre_trained models for various operations. https://huggingface.co/
I clicked on the image to text filter of models and sorted them by most downloads. I had around 2-4 models that could be used. 
  Models that could be used : 
  a. 
  
Resources used : 
1. https://michael-franke.github.io/npNLG/08-grounded-LMs/08c-NIC-pretrained.html
2. https://github.com/AIAnytime/Image-Caption-Generator-App/blob/main/Notebook%20Code/caption.ipynb
3. dataset: https://www.kaggle.com/datasets/prithvijaunjale/instagram-images-with-captions 
4. model: https://huggingface.co/nlpconnect/vit-gpt2-image-captioning  

Things I couldn't complete and would like to work on :

1. Here, resource #3 the dataset was supposed to be used to once again train the pretrained model, so that it would generate the catchy, exciting, innovative, captivating, creative, and engaging captions instead of just a description of the picture. That was the whole point of retraining the model, as the model has only been trained with general captions and their respective images. 
2. 
